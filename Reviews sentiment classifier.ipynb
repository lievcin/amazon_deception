{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll build a sentiment classifier using the review rating as the sentiment gold standard. \n",
    "#Treating this as a binary classification task, we can consider a 1-2 star review as negative, and a 4-5 star review as positive. \n",
    "#In order to achieve a roughly balanced data set, you may want to remove some of the positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, re\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.classify import SklearnClassifier\n",
    "from random import shuffle\n",
    "from sklearn.pipeline import Pipeline\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import some of the parsing and loading methods we had from previous tasks\n",
    "def parse_label(label):\n",
    "    if label == '__label2__':\n",
    "        return 'real'\n",
    "    else:\n",
    "        return 'fake'    \n",
    "\n",
    "def parse_verification(label):\n",
    "    if label == 'N':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1      \n",
    "\n",
    "def flatten(lst):\n",
    "    for el in lst:\n",
    "        if isinstance(el, list):\n",
    "            yield from el\n",
    "        else:\n",
    "            yield el    \n",
    "\n",
    "# Convert line from input file into an id/text/label tuple\n",
    "def parseReview(reviewLine):\n",
    "    # Should return a triple of an integer, a string containing the review, and a string indicating the label\n",
    "    return (reviewLine[0], \\\n",
    "            reviewLine[8] + ' ' + reviewLine[7], \\\n",
    "            parse_label(reviewLine[1]), \\\n",
    "            reviewLine[2], \\\n",
    "            parse_verification(reviewLine[3]))\n",
    "\n",
    "# load data from a file and append it to the rawData\n",
    "def loadData(path, Text=None):\n",
    "    with open(path) as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        next(reader, None)  # skip the headers        \n",
    "        for line in reader:\n",
    "            (Id, Text, Label, Rating, Verified) = parseReview(line)\n",
    "            rawData.append((Id, Text, Label, Rating, Verified))\n",
    "            \n",
    "#Loading our set\n",
    "rawData = []          # the filtered data from the dataset file (should be 21000 samples)\n",
    "reviewPath = 'amazon_reviews.txt'\n",
    "loadData(reviewPath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL vs FAKE F-K Score\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI4AAAHiCAYAAACOZYcfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOAIAAACg6/8HsBV3L9DTkfoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e3a14e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We'll want to put it all in a dataframe, and add some additional features\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import pyphen\n",
    "dic = pyphen.Pyphen(lang='en')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def averageLen(lst):\n",
    "    lengths = [len(i) for i in lst]\n",
    "    return 0 if len(lengths) == 0 else (float(sum(lengths)) / len(lengths)) \n",
    "\n",
    "\n",
    "names = ['doc_id', 'label', 'rating', 'verified_purchase', \\\n",
    "         'pr_category', 'pr_id', 'pr_title', 'review_title', 'review_text']\n",
    "data = pd.read_csv('amazon_reviews.txt', skiprows=[0], names=names, sep='\\t')\n",
    "data['verified_purchase'] = data['verified_purchase'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "data['label'] = data['label'].apply(lambda x: 'real' if x=='__label2__' else 'fake')\n",
    "data['review_text_length'] = data.apply(lambda row: len(row.review_text), axis=1)\n",
    "data['review_title_length'] = data.apply(lambda row: len(row.review_title), axis=1)\n",
    "data['tokenized_review'] = data.apply(lambda row: re.sub(r\"(\\w)([.,;:!-?'\\\"”\\)])\", r\"\\1 \\2\", row['review_text']), axis=1)\n",
    "data['tokenized_review'] = data.apply(lambda row: re.sub(r\"([.,;:!-?'\\\"“\\(])(\\w)\", r\"\\1 \\2\", row['tokenized_review']), axis=1)\n",
    "data['tokenized_review'] = data.apply(lambda row: re.sub(r\"<[^>]*>\", \"\", row['tokenized_review']), axis=1)\n",
    "data['tokenized_review'] = data.apply(lambda row: nltk.word_tokenize(row['tokenized_review'].lower()), axis=1)\n",
    "data['tokenized_review_string'] = data['tokenized_review'].apply(' '.join)\n",
    "data['tokens'] = data.apply(lambda row: [t for t in row['tokenized_review'] if t.isalpha()], axis=1)\n",
    "data['tokens'] = data.apply(lambda row: [t for t in row['tokens'] if t not in stop_words], axis=1)\n",
    "data['stopwords'] = data.apply(lambda row: [t for t in row['tokenized_review'] if t.isalpha()], axis=1)\n",
    "data['stopwords'] = data.apply(lambda row: [t for t in row['tokenized_review'] if t in stopwords.words('english')], axis=1)\n",
    "data['num_tokens'] = data.apply(lambda row: len(row['tokens']), axis=1)\n",
    "data['avg_len_tokens'] = data.apply(lambda row: averageLen(row['tokens']), axis=1)\n",
    "data['num_stopwords'] = data.apply(lambda row: len(row['stopwords']), axis=1)\n",
    "\n",
    "#Looking for the Flesch-Kincaid Readability measure across our pipulation\n",
    "data['word_count'] = data.apply(lambda row: len(row['tokenized_review']), axis=1)\n",
    "data['sent_count'] = data.apply(lambda row: len(sent_tokenize(row['review_text'])), axis=1)\n",
    "data['syll_count'] = data.apply(lambda row: len(list(flatten([dic.inserted(text).split('-') for text in row['tokenized_review']]))), axis=1)\n",
    "data['flesch_kincaid'] = data.apply(lambda row: 206.835 - 1.015*row['word_count']/row['sent_count'] - 84.6*row['syll_count']/row['word_count'], axis=1)\n",
    "\n",
    "real_data = data[data['label']== 'real'] \n",
    "fake_data = data[data['label']== 'fake'] \n",
    "\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(20,8)\n",
    "\n",
    "print('REAL vs FAKE F-K Score')\n",
    "plt.title('Real Reviews')\n",
    "real_data.hist('flesch_kincaid', bins=100, ax=axes[0])\n",
    "\n",
    "plt.title('Fake Reviews')\n",
    "fake_data.hist('flesch_kincaid', bins=100, ax=axes[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally on to our classifier, the first thing is to add a column that will serve to capture the sentiment\n",
    "def get_sent(rating):\n",
    "    if rating < 3:\n",
    "        sent = 'negative'\n",
    "    elif rating > 3:\n",
    "        sent = 'positive'\n",
    "    else:\n",
    "        sent = 'mweh'\n",
    "    return sent\n",
    "\n",
    "data['sentiment'] = data.apply(lambda row: get_sent(row['rating']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's make some vectors from our data, these will be used by the classifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['review_text'], data['sentiment'], test_size=0.33, random_state=1)\n",
    "\n",
    "# Initialize a CountVectorizer and Tfidf objects\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\", max_df=0.7)\n",
    "\n",
    "# Transform the training data using only the 'text' column values: count_train \n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data using only the 'review_text' column values: count_test \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 81.2%\n",
      "Confusion matrix:\n",
      "[[ 330   11  600]\n",
      " [  56    9  523]\n",
      " [  87   26 5288]]\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary modules for our classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Classifier accuracy: ' + str(round(100*score, 2)) + '%')\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['negative', 'mweh', 'positive'])\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 77.94%\n",
      "Confusion matrix:\n",
      "[[   0    0  941]\n",
      " [   0    0  588]\n",
      " [   0    0 5401]]\n"
     ]
    }
   ],
   "source": [
    "# What if we used to Tfidf vectors instead?\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(tfidf_train, y_train)\n",
    "pred = nb_classifier.predict(tfidf_test)\n",
    "\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Classifier accuracy: ' + str(round(100*score, 2)) + '%')\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['negative', 'mweh', 'positive'])\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of alphas: alphas\n",
    "import numpy as np\n",
    "alphas = np.arange(0, 1.5, .1)\n",
    "\n",
    "def train_and_predict(alpha):\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    nb_classifier.fit(tfidf_train, y_train)\n",
    "    pred = nb_classifier.predict(tfidf_test)\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ' + str(alpha) + ' score: ' + str(round(train_and_predict(alpha), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alphas = np.arange(0, 1.5, .1)\n",
    "\n",
    "def train_and_predict(alpha):\n",
    "    nb_classifier = MultinomialNB(alpha=alpha)\n",
    "    nb_classifier.fit(count_train, y_train)\n",
    "    pred = nb_classifier.predict(count_test)\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    return score\n",
    "\n",
    "for alpha in alphas:\n",
    "    print('Alpha: ' + str(alpha) + ' score: ' + str(round(train_and_predict(alpha), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigrams only:\n",
      "Classifier accuracy: 81.2%\n",
      "Confusion matrix:\n",
      "[[ 330   11  600]\n",
      " [  56    9  523]\n",
      " [  87   26 5288]]\n",
      "Ngrams:\n",
      "Classifier accuracy: 84.14%\n",
      "Confusion matrix:\n",
      "[[ 531   45  365]\n",
      " [ 111   42  435]\n",
      " [ 105   38 5258]]\n"
     ]
    }
   ],
   "source": [
    "#But we can also play with vectorizing ngrams instead of just unigrams\n",
    "\n",
    "\n",
    "print('Unigrams only:')\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Classifier accuracy: ' + str(round(100*score, 2)) + '%')\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['negative', 'mweh', 'positive'])\n",
    "print('Confusion matrix:')\n",
    "print(cm)\n",
    "\n",
    "print('Ngrams:')\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1, 7), analyzer='char')\n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "nb_classifier = MultinomialNB(alpha=0.2)\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print('Classifier accuracy: ' + str(round(100*score, 2)) + '%')\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['negative', 'mweh', 'positive'])\n",
    "print('Confusion matrix:')\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vectorizer = CountVectorizer(stop_words='english')\n",
    "# count_train = count_vectorizer.fit_transform(X_train)\n",
    "# count_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
